{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fd5792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 12:09:46,335\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-04-27 12:09:47,637\tINFO worker.py:1841 -- Started a local Ray instance. timestamp_ns=1745748587637344000\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.learning.dataset.p2pfl_dataset import P2PFLDataset\n",
    "from p2pfl.examples.cifar10.model.resnet_pytorch import model_build_fn\n",
    "from p2pfl.examples.cifar10.transforms import cifar10_transforms\n",
    "from p2pfl.learning.frameworks.pytorch.lightning_learner import LightningLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e65e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "data = P2PFLDataset.from_huggingface(\"p2pfl/CIFAR10\")\n",
    "data.set_batch_size(256)\n",
    "data.set_transforms(cifar10_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d36f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = model_build_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66418486",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LightningLearner.__init__() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Fit for 10 epochs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m learner = \u001b[43mLightningLearner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/p2pfl_all/p2pfl/p2pfl/utils/node_component.py:39\u001b[39m, in \u001b[36mAddrRequiredMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create an instance of the class and initialize the addr attribute to an empty string.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     instance = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     instance.addr = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
      "\u001b[31mTypeError\u001b[39m: LightningLearner.__init__() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "# Fit for 10 epochs\n",
    "learner = LightningLearner(\n",
    "    model=model,\n",
    "    data=data,\n",
    ")\n",
    "learner.set_epochs(1)\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    learner.fit()\n",
    "    learner.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Centralized Training\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from p2pfl.communication.protocols.protobuff.grpc import GrpcCommunicationProtocol\n",
    "from p2pfl.communication.protocols.protobuff.memory import MemoryCommunicationProtocol\n",
    "from p2pfl.learning.aggregators.scaffold import Scaffold\n",
    "from p2pfl.learning.dataset.partition_strategies import RandomIIDPartitionStrategy\n",
    "from p2pfl.management.logger import logger\n",
    "from p2pfl.node import Node\n",
    "from p2pfl.settings import Settings\n",
    "from p2pfl.utils.topologies import TopologyFactory, TopologyType\n",
    "from p2pfl.utils.utils import set_standalone_settings, wait_convergence, wait_to_finish\n",
    "\n",
    "\n",
    "            ,\n",
    "            partitions[i],\n",
    "            protocol=MemoryCommunicationProtocol() if protocol == \"memory\" else GrpcCommunicationProtocol(),\n",
    "            address=address,\n",
    "            aggregator=Scaffold() if aggregator == \"scaffold\" else None,\n",
    "        )\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    try:\n",
    "        adjacency_matrix = TopologyFactory.generate_matrix(topology, len(nodes))\n",
    "        TopologyFactory.connect_nodes(adjacency_matrix, nodes)\n",
    "\n",
    "        wait_convergence(nodes, n - 1, only_direct=False, wait=60)  # type: ignore\n",
    "\n",
    "        if r < 1:\n",
    "            raise ValueError(\"Skipping training, amount of round is less than 1\")\n",
    "\n",
    "        # Start Learning\n",
    "        nodes[0].set_start_learning(rounds=r, epochs=e)\n",
    "\n",
    "        # Wait and check\n",
    "        wait_to_finish(nodes, timeout=60 * 60)  # 1 hour\n",
    "\n",
    "        # Local Logs\n",
    "        if show_metrics:\n",
    "            local_logs = logger.get_local_logs()\n",
    "            if local_logs != {}:\n",
    "                logs_l = list(local_logs.items())[0][1]\n",
    "                #  Plot experiment metrics\n",
    "                for round_num, round_metrics in logs_l.items():\n",
    "                    for node_name, node_metrics in round_metrics.items():\n",
    "                        for metric, values in node_metrics.items():\n",
    "                            x, y = zip(*values)\n",
    "                            plt.plot(x, y, label=metric)\n",
    "                            # Add a red point to the last data point\n",
    "                            plt.scatter(x[-1], y[-1], color=\"red\")\n",
    "                            plt.title(f\"Round {round_num} - {node_name}\")\n",
    "                            plt.xlabel(\"Epoch\")\n",
    "                            plt.ylabel(metric)\n",
    "                            plt.legend()\n",
    "                            plt.show()\n",
    "\n",
    "            # Global Logs\n",
    "            global_logs = logger.get_global_logs()\n",
    "            if global_logs != {}:\n",
    "                logs_g = list(global_logs.items())[0][1]  # Accessing the nested dictionary directly\n",
    "                # Plot experiment metrics\n",
    "                for node_name, node_metrics in logs_g.items():\n",
    "                    for metric, values in node_metrics.items():\n",
    "                        x, y = zip(*values)\n",
    "                        plt.plot(x, y, label=metric)\n",
    "                        # Add a red point to the last data point\n",
    "                        plt.scatter(x[-1], y[-1], color=\"red\")\n",
    "                        plt.title(f\"{node_name} - {metric}\")\n",
    "                        plt.xlabel(\"Epoch\")\n",
    "                        plt.ylabel(metric)\n",
    "                        plt.legend()\n",
    "                        plt.show()\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        # Stop Nodes\n",
    "        for node in nodes:\n",
    "            node.stop()\n",
    "\n",
    "        if measure_time:\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parse args\n",
    "    args = __parse_args()\n",
    "\n",
    "    set_standalone_settings()\n",
    "\n",
    "    if args.profiling:\n",
    "        import os  # noqa: I001\n",
    "        import yappi  # type: ignore\n",
    "\n",
    "        # Start profiler\n",
    "        yappi.start()\n",
    "\n",
    "    # Set logger\n",
    "    if args.token != \"\":\n",
    "        logger.connect_web(\"http://localhost:3000/api/v1\", args.token)\n",
    "\n",
    "    # Seed\n",
    "    if args.seed is not None:\n",
    "        Settings.general.SEED = args.seed\n",
    "\n",
    "    # Launch experiment\n",
    "    try:\n",
    "        mnist(\n",
    "            args.nodes,\n",
    "            args.rounds,\n",
    "            args.epochs,\n",
    "            show_metrics=args.show_metrics,\n",
    "            measure_time=args.measure_time,\n",
    "            protocol=args.protocol,\n",
    "            framework=args.framework,\n",
    "            aggregator=args.aggregator,\n",
    "            reduced_dataset=args.reduced_dataset,\n",
    "            topology=args.topology,\n",
    "            batch_size=args.batch_size,\n",
    "        )\n",
    "    finally:\n",
    "        if args.profiling:\n",
    "            # Stop profiler\n",
    "            yappi.stop()\n",
    "            # Save stats\n",
    "            profile_dir = os.path.join(\"profile\", \"mnist\", str(uuid.uuid4()))\n",
    "            os.makedirs(profile_dir, exist_ok=True)\n",
    "            for thread in yappi.get_thread_stats():\n",
    "                yappi.get_func_stats(ctx_id=thread.id).save(f\"{profile_dir}/{thread.name}-{thread.id}.pstat\", type=\"pstat\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2pfl-Bw1EzmX_-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
